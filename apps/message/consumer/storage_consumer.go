package consumer

import (
	"context"
	"encoding/json"
	"fmt"
	"log"
	"time"
	"websocket-server/api/rest"
	"websocket-server/apps/message/model"
	"websocket-server/pkg/database"
	"websocket-server/pkg/kafka"
	"websocket-server/pkg/redis"

	"github.com/IBM/sarama"
	"go.mongodb.org/mongo-driver/bson"
)

// StorageConsumer å­˜å‚¨æ¶ˆè´¹è€…
type StorageConsumer struct {
	db       *database.MongoDB
	consumer *kafka.Consumer
	redis    *redis.RedisClient
}

// MessageEvent Kafkaæ¶ˆæ¯äº‹ä»¶ç»“æ„
type MessageEvent struct {
	Type      string          `json:"type"`
	Message   *rest.WSMessage `json:"message"`
	Timestamp int64           `json:"timestamp"`
}

// NewStorageConsumer åˆ›å»ºå­˜å‚¨æ¶ˆè´¹è€…
func NewStorageConsumer(db *database.MongoDB, redis *redis.RedisClient) *StorageConsumer {
	return &StorageConsumer{
		db:    db,
		redis: redis,
	}
}

// Start å¯åŠ¨å­˜å‚¨æ¶ˆè´¹è€…
func (s *StorageConsumer) Start(ctx context.Context, brokers []string) error {
	cfg := kafka.KafkaConfig{
		Brokers: brokers,
		GroupID: "storage-consumer-group",
		Topics:  []string{"message-events"},
	}

	consumer, err := kafka.InitConsumer(cfg, s)
	if err != nil {
		return err
	}

	s.consumer = consumer
	log.Printf("âœ… å­˜å‚¨æ¶ˆè´¹è€…å¯åŠ¨æˆåŠŸï¼Œç›‘å¬topic: message-events")

	return s.consumer.StartConsuming(ctx)
}

// HandleMessage å®ç° kafka.ConsumerHandler æ¥å£
func (s *StorageConsumer) HandleMessage(msg *sarama.ConsumerMessage) error {
	log.Printf("ğŸ“¥ å­˜å‚¨æ¶ˆè´¹è€…æ”¶åˆ°æ¶ˆæ¯: topic=%s, partition=%d, offset=%d",
		msg.Topic, msg.Partition, msg.Offset)

	defer func() {
		if r := recover(); r != nil {
			log.Printf("âŒ å­˜å‚¨æ¶ˆè´¹è€…å¤„ç†æ¶ˆæ¯æ—¶å‘ç”Ÿpanic: %v", r)
		}
	}()

	// å¹‚ç­‰æ€§æ£€æŸ¥ï¼šæ£€æŸ¥æ¶ˆæ¯æ˜¯å¦å·²å¤„ç†
	ctx := context.Background()
	if s.isMessageProcessed(ctx, msg.Partition, msg.Offset) {
		log.Printf("âœ… æ¶ˆæ¯å·²å¤„ç†ï¼Œè·³è¿‡: partition=%d, offset=%d", msg.Partition, msg.Offset)
		return nil
	}

	// è§£ææ¶ˆæ¯äº‹ä»¶
	var event MessageEvent
	if err := json.Unmarshal(msg.Value, &event); err != nil {
		log.Printf("âŒ è§£ææ¶ˆæ¯äº‹ä»¶å¤±è´¥: %v, åŸå§‹æ¶ˆæ¯: %s", err, string(msg.Value))
		return nil // è¿”å›nilé¿å…é‡è¯•
	}

	// æ ¹æ®äº‹ä»¶ç±»å‹å¤„ç†
	switch event.Type {
	case "new_message":
		if err := s.handleNewMessage(event.Message); err != nil {
			log.Printf("âŒ å¤„ç†æ–°æ¶ˆæ¯å¤±è´¥: %v", err)
			return nil // è¿”å›nilé¿å…é‡è¯•
		}

		// æ ‡è®°æ¶ˆæ¯å·²å¤„ç†
		if err := s.markMessageProcessed(ctx, msg.Partition, msg.Offset); err != nil {
			log.Printf("âŒ æ ‡è®°æ¶ˆæ¯å·²å¤„ç†å¤±è´¥: %v", err)
		}

		return nil
	default:
		log.Printf("âš ï¸  æœªçŸ¥çš„æ¶ˆæ¯äº‹ä»¶ç±»å‹: %s", event.Type)
		return nil
	}
}

// isMessageProcessed æ£€æŸ¥æ¶ˆæ¯æ˜¯å¦å·²å¤„ç†ï¼ˆå¹‚ç­‰æ€§æ£€æŸ¥ï¼‰
func (s *StorageConsumer) isMessageProcessed(ctx context.Context, partition int32, offset int64) bool {
	key := fmt.Sprintf("kafka:storage:%d:%d", partition, offset)
	exists, err := s.redis.Exists(ctx, key)
	if err != nil {
		log.Printf("âŒ æ£€æŸ¥æ¶ˆæ¯å¤„ç†çŠ¶æ€å¤±è´¥: %v", err)
		return false // å‡ºé”™æ—¶å‡è®¾æœªå¤„ç†ï¼Œå…è®¸é‡è¯•
	}
	return exists > 0 // Redis Existsè¿”å›å­˜åœ¨çš„keyæ•°é‡
}

// markMessageProcessed æ ‡è®°æ¶ˆæ¯å·²å¤„ç†
func (s *StorageConsumer) markMessageProcessed(ctx context.Context, partition int32, offset int64) error {
	key := fmt.Sprintf("kafka:storage:%d:%d", partition, offset)
	return s.redis.Set(ctx, key, "processed", time.Hour) // 1å°æ—¶è¿‡æœŸ
}

// handleNewMessage å¤„ç†æ–°æ¶ˆæ¯å­˜å‚¨ï¼ˆå¸¦å¹‚ç­‰æ€§ä¿æŠ¤ï¼‰
func (s *StorageConsumer) handleNewMessage(msg *rest.WSMessage) error {
	log.Printf("ğŸ’¾ å­˜å‚¨æ¶ˆæ¯: From=%d, To=%d, Content=%s, MessageID=%d", msg.From, msg.To, msg.Content, msg.MessageId)

	// æ£€æŸ¥MessageIDæ˜¯å¦å­˜åœ¨
	if msg.MessageId == 0 {
		log.Printf("âŒ MessageIDä¸º0ï¼Œè·³è¿‡å­˜å‚¨: From=%d, To=%d", msg.From, msg.To)
		return fmt.Errorf("MessageIDä¸èƒ½ä¸º0")
	}

	// è½¬æ¢ä¸ºMessageæ¨¡å‹å¹¶è®¾ç½®çŠ¶æ€
	message := &model.Message{
		// ä¸è®¾ç½®IDï¼Œè®©MongoDBè‡ªåŠ¨ç”Ÿæˆ_id
		MessageID: msg.MessageId, // ç›´æ¥ä½¿ç”¨Kafkaæ¶ˆæ¯ä¸­çš„MessageID
		From:      msg.From,
		To:        msg.To,
		GroupID:   msg.GroupId,
		Content:   msg.Content,
		MsgType:   msg.MessageType,
		Status:    0, // 0:æœªè¯»
		CreatedAt: time.Unix(msg.Timestamp, 0),
		UpdatedAt: time.Now(),
	}

	// å…ˆå°è¯•ç®€å•çš„æ’å…¥æ“ä½œï¼Œå¦‚æœé‡å¤åˆ™å¿½ç•¥
	collection := s.db.GetCollection("message")

	// æ£€æŸ¥æ¶ˆæ¯æ˜¯å¦å·²å­˜åœ¨
	var existingMsg model.Message
	err := collection.FindOne(context.Background(), bson.M{"message_id": msg.MessageId}).Decode(&existingMsg)
	if err == nil {
		// æ¶ˆæ¯å·²å­˜åœ¨ï¼Œè·³è¿‡æ’å…¥
		log.Printf("âœ… æ¶ˆæ¯å·²å­˜åœ¨(å¹‚ç­‰æ€§ä¿æŠ¤): From=%d, To=%d, MessageID=%d", msg.From, msg.To, msg.MessageId)
		return nil
	}

	// æ¶ˆæ¯ä¸å­˜åœ¨ï¼Œæ‰§è¡Œæ’å…¥
	result, err := collection.InsertOne(context.Background(), message)
	if err != nil {
		log.Printf("âŒ å­˜å‚¨æ¶ˆæ¯å¤±è´¥: %v", err)
		return err
	}

	log.Printf("âœ… æ¶ˆæ¯å­˜å‚¨æˆåŠŸ: From=%d, To=%d, Status=æœªè¯», MessageID=%d, InsertedID=%v",
		msg.From, msg.To, msg.MessageId, result.InsertedID)

	return nil
}

// Stop åœæ­¢æ¶ˆè´¹è€…
func (s *StorageConsumer) Stop() error {
	if s.consumer != nil {
		// TODO: å®ç°ä¼˜é›…åœæ­¢
		log.Printf("ğŸ›‘ å­˜å‚¨æ¶ˆè´¹è€…åœæ­¢")
	}
	return nil
}
